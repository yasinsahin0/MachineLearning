{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2193aec-0a5b-4314-91ce-a028c53c38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "import tensorflow as tf\n",
    "from scipy.io import wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c38a12-bc3c-45d5-8968-16dabb6cb781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_kirgizca_56.wav</td>\n",
       "      <td>kirgizca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_kirgizca_42.wav</td>\n",
       "      <td>kirgizca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_azerbaycan_20.wav</td>\n",
       "      <td>azerbaycan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6_turkmence_46.wav</td>\n",
       "      <td>turkmence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6_turkmence_52.wav</td>\n",
       "      <td>turkmence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_name  class_name\n",
       "0    2_kirgizca_56.wav    kirgizca\n",
       "1    2_kirgizca_42.wav    kirgizca\n",
       "2  3_azerbaycan_20.wav  azerbaycan\n",
       "3   6_turkmence_46.wav   turkmence\n",
       "4   6_turkmence_52.wav   turkmence"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dataset_path='splitSound/'\n",
    "metadata=pd.read_csv('data.csv')\n",
    "mfcc = 60\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc0f5837-64d5-44f4-a277-2aba3f730cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(filename):\n",
    "    audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=mfcc)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24deb6d3-d209-4230-bbc2-ee1ac6bfb129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4632it [02:46, 27.78it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),str(row[\"file_name\"]))\n",
    "    final_class_labels=row[\"class_name\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0545abb5-c71e-433a-9f21-9659cb241d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-348.59406, 101.22915, 17.085117, 37.934284, ...</td>\n",
       "      <td>kirgizca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-265.22748, 100.98364, 15.282236, 15.134626, ...</td>\n",
       "      <td>kirgizca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-316.61432, 136.03163, 15.960988, 25.720314, ...</td>\n",
       "      <td>azerbaycan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-254.13887, 134.00977, -27.66474, 49.05436, -...</td>\n",
       "      <td>turkmence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-270.3439, 135.30635, -0.20712668, 54.928783,...</td>\n",
       "      <td>turkmence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature       class\n",
       "0  [-348.59406, 101.22915, 17.085117, 37.934284, ...    kirgizca\n",
       "1  [-265.22748, 100.98364, 15.282236, 15.134626, ...    kirgizca\n",
       "2  [-316.61432, 136.03163, 15.960988, 25.720314, ...  azerbaycan\n",
       "3  [-254.13887, 134.00977, -27.66474, 49.05436, -...   turkmence\n",
       "4  [-270.3439, 135.30635, -0.20712668, 54.928783,...   turkmence"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df = pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374f69e3-0716-4c59-8d33-7afd5d84a60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4632, 60)\n",
      "(4632,)\n"
     ]
    }
   ],
   "source": [
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad0f33ae-b2cb-46e7-bb1d-fe72fb67cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6917bce8-52b2-4a88-8a0c-988ab0e6fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3078421-d55c-432a-8abd-50b7b594f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc802282-39a3-4e53-9e27-4a28024fd58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 10:01:56.053219: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-25 10:01:56.053573: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "# 1. hidden layer\n",
    "model.add(Dense(125,input_shape=(mfcc,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# 2. hidden layer\n",
    "model.add(Dense(250))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# 3. hidden layer\n",
    "model.add(Dense(125))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e32b252c-bf9d-4de5-9313-2dfd6b6b82db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 125)               7625      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 125)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 125)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 250)               31500     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 250)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 250)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 125)               31375     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 125)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 125)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 882       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,382\n",
      "Trainable params: 71,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "330e54ee-f911-4f8b-a875-8a1c1cf1f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752d927-7399-437e-8a2e-86412b98bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochscount = 50\n",
    "num_batch_size = 32\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=epochscount, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1518477-87ff-4969-913f-88e9bdb442dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9730313420295715\n",
      "0.07995288074016571\n"
     ]
    }
   ],
   "source": [
    "validation_test_set_accuracy = model.evaluate(X_test,y_test,verbose=0)\n",
    "print(validation_test_set_accuracy[1])\n",
    "print(validation_test_set_accuracy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ee4ea25-9ebc-4974-b1c2-66bb42272bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 10:05:15.165673: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 1.2810433e-35, 2.4074748e-27, ..., 5.2381563e-30,\n",
       "        1.0000000e+00, 0.0000000e+00],\n",
       "       [5.7457906e-11, 5.1263827e-10, 4.5218374e-11, ..., 8.9220897e-10,\n",
       "        3.7254437e-14, 1.0000000e+00],\n",
       "       [8.5289276e-10, 2.4072997e-05, 2.1360377e-07, ..., 2.3177108e-05,\n",
       "        7.3220356e-08, 3.6700069e-06],\n",
       "       ...,\n",
       "       [9.2358130e-04, 2.2045854e-03, 2.6213692e-03, ..., 6.0413452e-03,\n",
       "        1.7356714e-04, 9.8739129e-01],\n",
       "       [4.7762384e-08, 9.9661583e-01, 1.4190709e-03, ..., 9.7282154e-06,\n",
       "        2.0017394e-05, 1.3978879e-03],\n",
       "       [8.9941655e-13, 9.6028074e-08, 4.1929360e-10, ..., 1.4443974e-07,\n",
       "        3.7639183e-10, 7.5438663e-08]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b7ad6bf-0fd3-4a30-bc77-9530390ddc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ozbekce\n",
      "turkmence\n",
      "ozbekce\n",
      "ozbekce\n",
      "ozbekce\n",
      "ozbekce\n",
      "ozbekce\n",
      "ozbekce\n",
      "uygurca\n",
      "turkmence\n"
     ]
    }
   ],
   "source": [
    "result_classes = [\"azerbaycan\",\"kazakca\", \"uygurca\",\"kirgizca\",\"tatarca\",\"turkmence\",\"ozbekce\"]\n",
    "file_name = \"ozbekce\"\n",
    "for i in range(1,11):\n",
    "    filename=\"testSound/\"+file_name+\"_\"+str(i)+\".wav\"\n",
    "    sound_signal, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=sound_signal, sr=sample_rate, n_mfcc=mfcc)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    mfccs_scaled_features = mfccs_scaled_features.reshape(1,-1)\n",
    "    result_array = model.predict(mfccs_scaled_features)\n",
    "    result = np.argmax(result_array[0])\n",
    "    print(result_classes[result]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0131050-d2c4-44cc-beae-00f5e1c631b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sınıf : azerbaycan -- Doğruluk : % 1\n",
      "Sınıf : kazakca -- Doğruluk : % 2\n",
      "Sınıf : uygurca -- Doğruluk : % 87\n",
      "Sınıf : ozbekce -- Doğruluk : % 1\n",
      "Sınıf : tatarca -- Doğruluk : % 7\n",
      "Sınıf : turkmence -- Doğruluk : % 2\n",
      "Sınıf : kirgizca -- Doğruluk : % 1\n",
      "uygurca\n"
     ]
    }
   ],
   "source": [
    "result_classes = [\"azerbaycan\",\"kazakca\", \"uygurca\",\"ozbekce\",\"tatarca\",\"turkmence\",\"kirgizca\"]\n",
    "filename=\"testSound/kirgizca_6.wav\"\n",
    "sound_signal, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=sound_signal, sr=sample_rate, n_mfcc=mfcc)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "mfccs_scaled_features = mfccs_scaled_features.reshape(1,-1)\n",
    "result_array = model.predict(mfccs_scaled_features)\n",
    "for a in range(0,len(result_array[0])):\n",
    "    print(\"Sınıf : {0} -- Doğruluk : % {1}\".format(result_classes[a],int(round(float(result_array[0][a]),2)*100)))\n",
    "result = np.argmax(result_array[0])\n",
    "print(result_classes[result]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f49238-a6a4-4fd5-b3b6-c298abac8536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
